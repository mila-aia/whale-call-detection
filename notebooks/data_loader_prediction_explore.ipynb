{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM, classification + regression on Spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from whale.data_io.data_loader import WhaleDataModule\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "import numpy  as np\n",
    "from whale.models import LSTM\n",
    "from matplotlib import pyplot as plt\n",
    "from whale.utils.spectrogram import show_spectrogram\n",
    "\n",
    "seed_everything(1234)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt_path = '/network/projects/aia/whale_call/mlruns/4/f0bdb4ba8a9048d085d2991bcdd0e8b9/artifacts/model/checkpoints/epoch=20-step=6531/'\n",
    "best_model_path  = ckpt_path+'epoch=20-step=6531.ckpt'\n",
    "model = LSTM.load_from_checkpoint(best_model_path)\n",
    "model.eval();\n",
    "model.to(device);\n",
    "\n",
    "\n",
    "whale_dm = WhaleDataModule(\n",
    "    data_dir=\"/network/projects/aia/whale_call/LABELS/fw_HQ_filt_mixed\", batch_size=1,data_type=\"spec\"\n",
    ")\n",
    "whale_dm.setup()\n",
    "\n",
    "ds_sel = whale_dm.valid_ds\n",
    "dataset_size = len(ds_sel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 6\n",
    "idx_rands = np.random.choice(dataset_size, num_samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_length = 201\n",
    "dt = 0.01\n",
    "t_axis = np.arange(0,sig_length)*dt\n",
    "label_dict = {0:'Noise',1:'FW Call'}\n",
    "fig,axs = plt.subplots(2,num_samples,figsize=(16,6))\n",
    "for i in range(num_samples):\n",
    "    idx_rand = idx_rands[i]\n",
    "    data_sel = train_ds[idx_rand]\n",
    "    sig = data_sel['sig']\n",
    "    spectrogram = data_sel['spec']\n",
    "\n",
    "    class_logits, reg_out = model(spectrogram.unsqueeze(0).to(device))\n",
    "    class_pred = torch.argmax(class_logits,axis=1)\n",
    "    \n",
    "    axs[0][i].plot(t_axis,sig[0],color='grey');\n",
    "    axs[0][i].set_title(f\"Target Label: {label_dict[data_sel['target_label']]}\\n Pred Label:{label_dict[class_pred.cpu().detach().numpy()[0]]}\")\n",
    "    # add axis labels\n",
    "    axs[0][i].set_xlabel('Time (s)')\n",
    "    axs[0][i].set_ylabel('Normalized Amplitude')\n",
    "\n",
    "    # plot spectrogram and add vertical lines representing target time and predicted time\n",
    "    show_spectrogram(sig[0],axes=axs[1][i],samp_rate=100,per_lap=0.9, wlen=0.5, mult=4)\n",
    "    axs[1][i].axvline(x=data_sel['target_time'],color='red')\n",
    "    axs[1][i].axvline(x=reg_out.cpu().detach().numpy(),color='green')\n",
    "    # add axis labels\n",
    "    axs[1][i].set_xlabel('Time (s)')\n",
    "    axs[1][i].set_ylabel('Frequency (Hz)')\n",
    "    # show legend\n",
    "    # axs[1][i].legend(['t_trgt','t_pred'])\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('prediction_examples_baseline_LSTM_cls_reg.png',dpi=300)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms and confusion matrix (Warning: Long runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "import numpy as np\n",
    "test_loader = whale_dm.test_dataloader()\n",
    "test_size = len(test_loader)\n",
    "trainer = Trainer( accelerator='auto')\n",
    "model =LSTM(input_dim= 129 ,hidden_dim=128,reg_loss_weight=0.5,num_layers=3,bidirectional=False)\n",
    "prediction_output=trainer.predict(model, dataloaders=test_loader, ckpt_path=best_model_path)\n",
    "label_pred=np.vstack([prediction['label'].reshape(-1,1).numpy() for prediction in prediction_output])\n",
    "time_pred=np.vstack([prediction['time'].reshape(-1,1).numpy()   for prediction in prediction_output])\n",
    "\n",
    "label_true = []\n",
    "time_true = []\n",
    "for batch in test_loader:\n",
    "    label_true.append(batch['target_label'].reshape(-1,1).numpy())\n",
    "    time_true.append(batch['target_time'].reshape(-1,1).numpy())\n",
    "label_true = np.vstack([label.reshape(-1,1) for label in label_true])\n",
    "time_true = np.vstack([time.reshape(-1,1) for time in time_true])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "18e4029a2df6ccc2263d21f79565dbbc86418c6d27dddb59d3273cc9e38186c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
