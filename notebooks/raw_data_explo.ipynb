{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "This notebook contains the code to load, preprocess, and explore the labeled whale call detection dataset\n",
    "\n",
    "* [1. Load data](#loaddata)\n",
    "* [2. Stats of raw data](#stats)\n",
    "    * [Type of files](#typefiles)\n",
    "    * [Number of file per station](#stationfiles)\n",
    "* [3. Visualy explore data](#vizexp)\n",
    "    * [Obspy](#obspy)\n",
    "    * [Pysmo](#pysmo)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data <a class=\"anchor\" id=\"loaddata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "directory_path = '../whale-detection-signal-processing/data/sac_data/'\n",
    "list_files = glob.glob(directory_path+'/*/*/*.SAC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of files:\",len(list_files))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats of raw data <a class=\"anchor\" id=\"stats\"></a>\n",
    "\n",
    "### Type of files <a class=\"anchor\" id=\"typefiles\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extensions = Counter([file[-7:-4] for file in list_files]).keys()\n",
    "\n",
    "for extension in file_extensions:\n",
    "    print(\"{}: {} files\".format(extension,sum(extension in s for s in list_files)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of files per station <a class=\"anchor\" id=\"stationfiles\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_names = [\"PMAQ\",\"ICQ\",\"SNFQ\",\"RISQ\",\"SMQ\",\"CNQ\"]\n",
    "\n",
    "for sta in sta_names:\n",
    "    sta_files = [s for s in list_files if sta in s.split('/')[-1]]\n",
    "    print(\"{}: {} files\".format(sta,sum(sta in s for s in list_files if sta in s.split('/')[-1])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stations and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    columns=file_extensions,\n",
    "    index=[\"PMAQ\",\"ICQ\",\"SNFQ\",\"RISQ\",\"SMQ\",\"CNQ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sta_names = [\"PMAQ\",\"ICQ\",\"SNFQ\",\"RISQ\",\"SMQ\",\"CNQ\"]\n",
    "\n",
    "for sta in sta_names:\n",
    "    sta_files = [s for s in list_files if sta in s.split('/')[-1]]\n",
    "    for extension in file_extensions:\n",
    "        df.xs(sta)[extension] = sum(extension in s for s in sta_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['Total']= df.sum()\n",
    "df['Total'] = df.sum(axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual exploration <a class=\"anchor\" id=\"vizexp\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHALE_TYPE = 'bw' # fw bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_d = pd.read_csv('data/'+WHALE_TYPE+'c_preprocessed.csv')\n",
    "print(\"Total number of Whale detection:\",label_d.detection_id.nunique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Select random detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = label_d[label_d.detection_id == random.choice(label_d.detection_id.unique())]\n",
    "detection_id = detection['detection_id'].max()\n",
    "date = detection['date'].max()\n",
    "datetime_start = detection['datetime_start'].max()\n",
    "station_name = detection['station_name'].max()\n",
    "num_calls_in_detection = detection['num_calls_in_detection'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Station name: {}\".format(station_name))\n",
    "print(\"Date detection: {} | Time detection: {}\".format(date,datetime_start))\n",
    "print(\"Number of calls on this detection: {}\".format(num_calls_in_detection))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Match label data with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from obspy import UTCDateTime\n",
    "from datetime import date\n",
    "from datetime import timezone\n",
    "\n",
    "df_time_changed = detection.copy()\n",
    "df_time_changed['datetime_datetime'] = df_time_changed.datetime.apply(lambda x : datetime.datetime.strptime(x[:-3], '%Y-%m-%d %H:%M:%S.%f'))\n",
    "df_time_changed['datetime_UTCDateTime'] = df_time_changed.datetime.apply(lambda x : UTCDateTime(x))\n",
    "df_time_changed['datetime_ordinal'] = df_time_changed.datetime_datetime.apply(lambda x : date.toordinal(x))\n",
    "df_time_changed['datetime_tz'] = df_time_changed.datetime_datetime.apply(lambda x : x.replace(tzinfo=timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df_time_changed.groupby('detection_id').agg(\n",
    "    min_time_utc=('datetime_UTCDateTime', 'min'), \n",
    "    max_time_utc=('datetime_UTCDateTime', 'max'),\n",
    "    min_time=('datetime_datetime', 'min'), \n",
    "    max_time=('datetime_datetime', 'max'),\n",
    "    min_time_ordinal=('datetime_ordinal', 'min'), \n",
    "    max_time_ordinal=('datetime_ordinal', 'max'),\n",
    "    datetz_list=('datetime_tz', list), \n",
    "    datenum_list=('Datenum', list ),\n",
    "    date_list=('datetime',  list),\n",
    "    ).reset_index()\n",
    "\n",
    "grouped_df['length'] = grouped_df['min_time'] - grouped_df['max_time']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obspy <a class=\"anchor\" id=\"obspy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy import read\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "date = detection['date'].max()\n",
    "date_str = ''.join(date.split('-'))\n",
    "directory_path = '../whale-detection-signal-processing/data/sac_data/'+date_str[:6]+'*'+station_name+'*/'+date_str+'/'\n",
    "files = glob.glob(directory_path+'*'+station_name+'*.SAC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threechannels = read(files[0])\n",
    "for file_id in range(1,len(files)):\n",
    "    threechannels += read(files[file_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threechannels.plot(size=(1200, 400))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Fin Whale calls for one detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "with open('../whale-detection-signal-processing/config/config.yml', 'r') as file:\n",
    "    param_data = yaml.safe_load(file)['whale_constant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(len(threechannels),1,figsize=(15,10))\n",
    "for index,trace in enumerate(threechannels):\n",
    "    starttime = df_time_changed['datetime_UTCDateTime'].min()\n",
    "    endtime = starttime + param_data[WHALE_TYPE][\"window\"]\n",
    "\n",
    "    # Plot trace of \n",
    "    sliced = trace.slice(starttime - 50, endtime + 50 )\n",
    "    ax[index].plot(sliced.times(\"matplotlib\"), sliced.data, \"b-\")\n",
    "\n",
    "    # Plot whales detections on timeline\n",
    "    for date in df_time_changed['datetime_tz'].values:\n",
    "        ax[index].axvline(\n",
    "            x=date,\n",
    "            color='r',\n",
    "            label=\"whale Call\")\n",
    "\n",
    "    ax[index].xaxis_date()\n",
    "    ax[index].set_xlabel('Time of day', fontweight='bold')\n",
    "    ax[index].set_ylabel('Amplitude', fontweight='bold')\n",
    "    ax[index].set_title(\n",
    "        \"{} calls | {} coordinates |Starting time: {} | Date: {}\".format(\n",
    "            param_data[WHALE_TYPE][\"name\"],\n",
    "            sliced.stats.channel,\n",
    "            df_time_changed.datetime_start.min(),\n",
    "            df_time_changed.date.min(),\n",
    "            ),\n",
    "        fontweight='bold')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply signal processing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots(len(threechannels),2,figsize=(15,10))\n",
    "for index,trace in enumerate(threechannels):\n",
    "\n",
    "    # Plot trace of \n",
    "    sliced = trace.slice(\n",
    "        starttime - 20, \n",
    "        endtime + 20 )\n",
    "\n",
    "    # Filtering with a lowpass on a copy of the original Trace\n",
    "    tr_filt = sliced.copy()\n",
    "    tr_filt.filter(\n",
    "        'bandpass', \n",
    "        freqmin=param_data[WHALE_TYPE][\"low_cut_bandpass\"],\n",
    "        freqmax=param_data[WHALE_TYPE][\"high_cut_bandpass\"],\n",
    "        corners=2, \n",
    "        zerophase=True)\n",
    "\n",
    "    # Now let's plot the raw and filtered data...\n",
    "    t = np.arange(0, sliced.stats.npts / sliced.stats.sampling_rate, sliced.stats.delta)\n",
    "    ax[index,0].plot(t, sliced.data)\n",
    "    ax[index,0].set_ylabel('Raw Data')\n",
    "    ax[index,0].set_xlabel('Time [s]')\n",
    "    ax[index,0].set_title('Raw signal | {} coordinates'.format(sliced.stats.channel))\n",
    "\n",
    "    ax[index,1].plot(t, tr_filt.data)\n",
    "    ax[index,1].set_ylabel('Bandpassed Data')\n",
    "    ax[index,1].set_xlabel('Time [s]')\n",
    "    ax[index,1].set_title('Bandpassed signal ({} Hz <-> {} Hz) | {} coordinates'.format(\n",
    "        param_data[WHALE_TYPE][\"low_cut_bandpass\"],\n",
    "        param_data[WHALE_TYPE][\"high_cut_bandpass\"],\n",
    "        sliced.stats.channel))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_filt.spectrogram(title='SPECTROGRAM')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add up all signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "list_of_list = np.add(threechannels[0].data, threechannels[1].data, threechannels[2].data)\n",
    "trace = threechannels[0]\n",
    "\n",
    "trace.data = list_of_list\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "# Plot trace of \n",
    "sliced = trace.slice(\n",
    "    starttime - 20, \n",
    "    endtime + 20 )\n",
    "\n",
    "# Filtering with a lowpass on a copy of the original Trace\n",
    "tr_filt = sliced.copy()\n",
    "tr_filt.filter(\n",
    "    'bandpass', \n",
    "    freqmin=param_data[WHALE_TYPE][\"low_cut_bandpass\"],\n",
    "    freqmax=param_data[WHALE_TYPE][\"high_cut_bandpass\"],\n",
    "    corners=2, \n",
    "    zerophase=True)\n",
    "\n",
    "# Now let's plot the raw and filtered data...\n",
    "t = np.arange(0, sliced.stats.npts / sliced.stats.sampling_rate, sliced.stats.delta)\n",
    "ax[0].plot(t, sliced.data)\n",
    "ax[0].set_ylabel('Raw Data')\n",
    "ax[0].set_xlabel('Time [s]')\n",
    "\n",
    "ax[1].plot(t, tr_filt.data)\n",
    "ax[1].set_ylabel('Bandpassed Data')\n",
    "ax[1].set_xlabel('Time [s]');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_filt.spectrogram(title='SPECTROGRAM')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pysmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysmo import SacIO\n",
    "my_sac_EHZ = SacIO.from_file(files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "data = my_sac_EHZ.data\n",
    "print(\"Number of samples : {}\".format(len(data)))\n",
    "\n",
    "# Read the sampling rate\n",
    "delta = my_sac_EHZ.delta\n",
    "print(\"Sampling rate: {} seconds\".format(delta))\n",
    "print(\"Sampling frequency: {}\".format(1/delta))\n",
    "total_seconds = len(data)*delta\n",
    "print(\"Total seconds: {} seconds\".format(total_seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ISO 8601 format of GMT reference date: \",my_sac_EHZ.kzdate) # ISO 8601 format of GMT reference date.\n",
    "print(\"Alphanumeric form of GMT reference time: \",my_sac_EHZ.kztime) # Alphanumeric form of GMT reference time.\n",
    "print(\"Station name: \",my_sac_EHZ.kstnm) # Station name.\n",
    "print(\"Name of seismic network: \",my_sac_EHZ.knetwk) # Name of seismic network.\n",
    "print(\"TRUE if data is evenly spaced: \",my_sac_EHZ.leven) # TRUE if data is evenly spaced\n",
    "print(\"Beginning value of the independent variable: \",my_sac_EHZ.b) # Beginning value of the independent variable.\n",
    "print(\"Ending value of the independent variable: \",my_sac_EHZ.e) # Ending value of the independent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,4))\n",
    "ax.plot(data)\n",
    "ax.set_xlabel('Time', fontsize=15)\n",
    "ax.set_ylabel('Amplitude', fontsize=15);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signal-processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd5bd5b3cde2f6b22ba9fb4d1e8077806a6ad2000fbc2bec6d807c66178fbb91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
