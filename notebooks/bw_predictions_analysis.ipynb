{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW High Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from whale.data_io.data_loader import WhaleDataModule\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "import numpy  as np\n",
    "from whale.models import LSTM\n",
    "from matplotlib import pyplot as plt\n",
    "from whale.utils.spectrogram import show_spectrogram, cal_spectrogram\n",
    "\n",
    "seed_everything(1234)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ckpt_path = '/network/projects/aia/whale_call/mlruns/756039190186882702/e01ee35dc34641e5ac7141b1864936dd/artifacts/model/checkpoints/epoch=29-step=4350/'\n",
    "\n",
    "ckpt_path = \"/network/projects/aia/whale_call/mlruns/214176838239808987/ef4956f212324b7fb1bcf1436c577743/artifacts/model/checkpoints/epoch=7-step=128/\"\n",
    "\n",
    "\n",
    "best_model_path  = ckpt_path+'epoch=7-step=128.ckpt'\n",
    "model = LSTM.load_from_checkpoint(best_model_path)\n",
    "model.eval();\n",
    "model.to(device);\n",
    "\n",
    "\n",
    "whale_dm = WhaleDataModule(\n",
    "    data_dir=\"/network/projects/aia/whale_call/LABELS/BWC_3CH_HQ\", batch_size=1,data_type=\"spec\"\n",
    ")\n",
    "whale_dm.setup()\n",
    "\n",
    "ds_sel = whale_dm.valid_ds\n",
    "dataset_size = len(ds_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 6\n",
    "idx_rands = np.random.choice(dataset_size, num_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_length = 1601\n",
    "dt = 0.01\n",
    "t_axis = np.arange(0,sig_length)*dt\n",
    "label_dict = {0:'Noise',1:'BW Call'}\n",
    "fig,axs = plt.subplots(2,num_samples,figsize=(16,6))\n",
    "for i in range(num_samples):\n",
    "    idx_rand = idx_rands[i]\n",
    "    data_sel = ds_sel[idx_rand]\n",
    "    sig = data_sel['sig']\n",
    "    spectrogram = data_sel['spec']\n",
    "\n",
    "    class_logits, reg_out = model(spectrogram.unsqueeze(0).to(device))\n",
    "    class_pred = torch.argmax(class_logits,axis=1)\n",
    "    \n",
    "    axs[0][i].plot(t_axis,sig[0],color='grey');\n",
    "    axs[0][i].set_title(f\"Target Label: {label_dict[data_sel['target_label']]}\\n Pred Label:{label_dict[class_pred.cpu().detach().numpy()[0]]}\")\n",
    "    # add axis labels\n",
    "    axs[0][i].set_xlabel('Time (s)')\n",
    "    axs[0][i].set_ylabel('Normalized Amplitude')\n",
    "\n",
    "    # plot spectrogram and add vertical lines representing target time and predicted time\n",
    "    ## first get the time and freq bins\n",
    "    _,freq,time=cal_spectrogram(sig[0],samp_rate=100,per_lap=0.9, wlen=0.5, mult=4)\n",
    "    # calculate half bin width\n",
    "    halfbin_time = (time[1] - time[0]) / 2.0\n",
    "    halfbin_freq = (freq[1] - freq[0]) / 2.0\n",
    "    # this method is much much faster!\n",
    "    specgram = np.flipud(spectrogram.T)\n",
    "    # center bin\n",
    "    extent = (\n",
    "        time[0] - halfbin_time,\n",
    "        time[-1] + halfbin_time,\n",
    "        freq[0] - halfbin_freq,\n",
    "        freq[-1] + halfbin_freq,\n",
    "    )\n",
    "    axs[1][i].imshow(specgram, interpolation=\"nearest\", extent=extent)\n",
    "\n",
    "    # show_spectrogram(sig[0],axes=axs[1][i],samp_rate=100,per_lap=0.9, wlen=0.5, mult=4)\n",
    "    axs[1][i].axvline(x=data_sel['target_time'],color='red')\n",
    "    axs[1][i].axvline(x=reg_out.cpu().detach().numpy(),color='green')\n",
    "    axs[1][i].set_xlim([0,time[-1]])\n",
    "    axs[1][i].axis(\"tight\")\n",
    "    # ax.grid(False)\n",
    "\n",
    "    # add axis labels\n",
    "    axs[1][i].set_xlabel('Time (s)')\n",
    "    axs[1][i].set_ylabel('Frequency (Hz)')\n",
    "    # show legend\n",
    "    axs[1][i].legend(['t_trgt','t_pred'])\n",

    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('prediction_examples_baseline_LSTM_cls_reg.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BW Low Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from whale.data_io.data_loader import WhaleDataModule\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "import numpy  as np\n",
    "from whale.models import LSTM\n",
    "from matplotlib import pyplot as plt\n",
    "from whale.utils.spectrogram import show_spectrogram\n",
    "\n",
    "seed_everything(1234)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt_path = \"/network/projects/aia/whale_call/mlruns/214176838239808987/cca1b8e4231e4f5a82c8d5937f820f23/artifacts/model/checkpoints/epoch=29-step=19350/\"\n",
    "\n",
    "\n",
    "best_model_path  = ckpt_path+'epoch=29-step=19350.ckpt'\n",
    "model = LSTM.load_from_checkpoint(best_model_path)\n",
    "model.eval();\n",
    "model.to(device);\n",
    "\n",
    "\n",
    "whale_dm = WhaleDataModule(\n",
    "    data_dir=\"/network/projects/aia/whale_call/LABELS/BWC_3CH_LQ\", batch_size=1,data_type=\"spec\"\n",
    ")\n",
    "whale_dm.setup()\n",
    "\n",
    "ds_sel = whale_dm.valid_ds\n",
    "dataset_size = len(ds_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 6\n",
    "idx_rands = np.random.choice(dataset_size, num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_length = 1601\n",
    "dt = 0.01\n",
    "t_axis = np.arange(0,sig_length)*dt\n",
    "label_dict = {0:'Noise',1:'BW Call'}\n",
    "fig,axs = plt.subplots(2,num_samples,figsize=(16,6))\n",
    "for i in range(num_samples):\n",
    "    idx_rand = idx_rands[i]\n",
    "    data_sel = ds_sel[idx_rand]\n",
    "    sig = data_sel['sig']\n",
    "    spectrogram = data_sel['spec']\n",
    "\n",
    "    class_logits, reg_out = model(spectrogram.unsqueeze(0).to(device))\n",
    "    class_pred = torch.argmax(class_logits,axis=1)\n",
    "    \n",
    "    axs[0][i].plot(t_axis,sig[0],color='grey');\n",
    "    axs[0][i].set_title(f\"Target Label: {label_dict[data_sel['target_label']]}\\n Pred Label:{label_dict[class_pred.cpu().detach().numpy()[0]]}\")\n",
    "    # add axis labels\n",
    "    axs[0][i].set_xlabel('Time (s)')\n",
    "    axs[0][i].set_ylabel('Normalized Amplitude')\n",
    "\n",
    "    # plot spectrogram and add vertical lines representing target time and predicted time\n",
    "    show_spectrogram(sig[0],axes=axs[1][i],samp_rate=100,per_lap=0.9, wlen=0.5, mult=4)\n",
    "    axs[1][i].axvline(x=data_sel['target_time'],color='red')\n",
    "    axs[1][i].axvline(x=reg_out.cpu().detach().numpy(),color='green')\n",
    "    # add axis labels\n",
    "    axs[1][i].set_xlabel('Time (s)')\n",
    "    axs[1][i].set_ylabel('Frequency (Hz)')\n",
    "    # show legend\n",
    "    # axs[1][i].legend(['t_trgt','t_pred'])\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig('prediction_examples_baseline_LSTM_cls_reg.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whale",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"

  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
